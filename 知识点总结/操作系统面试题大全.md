为什么要分用户态和内核态

安全性，保护os内核，用户态程序必须通过系统调用向内核（内存管理、文件、硬件设备等）请求服务，保护内核和关键资源不被非法访问或破坏。

内核统一管理系统资源，优化操作效率，内核可以更好调度和分配系统资源，提高系统运行效率



# 什么是上下文切换

> 各个进程之间 共享cpu， 不同的时候 进程之间需要进行切换，这就是进程的上下文切换

os保存当前进程（线程）状态，并恢复另一个进程（线程）状态，执行，

保存加载 寄存器的内容，程序计数器，堆栈指针等

cpu保存前一个任务的上下文（cpu寄存器和pc），加载新任务的上下文，最后跳转到pc指向的位置，运行新任务。

# 进程的上下文切换

进程由内核管理和调度，进程的切换发生在内核态

进程上下文里面：虚拟内存、栈、全局变量等用户空间的资源，还有内核堆栈、寄存器等内核空间的资源

![image-20240827213431975](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827213431975.png)

cpu划分成一段段时间片，某个进程时间片耗尽，就从运行态变为就绪态，os从就绪队列选择另一进程运行，这里就需要切换

# 进程控制块PCB

![image-20240827214025893](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827214025893.png)

每个PCB 通过链表 方式组织起来，把具有相同状态的进程 连在一起， 组成各种队列：就绪队列、阻塞队列等

为什么用链表？进程创建、销毁等调度导致进程状态发生变化，链表能够更加灵活插入和删除

![image-20240827214108592](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827214108592.png)

# 进程的状态

创建、结束

就绪、运行、阻塞

挂起（阻塞挂起、就绪挂起）：进程没有占用实际的物理内存空间的情况，就是挂起状态。阻塞挂起是 进程在外存等待某个事件出现，就绪挂起，进程在外存等，只要进入内存，就立即执行

![image-20240827214412647](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827214412647.png)

# 还有哪些场景会发生上下文切换


![image-20240827213608763](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827213608763.png)

# 操作系统角度谈谈 堆和栈



# 进程和线程的理解

![image-20240824225559591](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240824225559591.png)

![image-20240827213723883](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827213723883.png)

同一个进程内的线程切换快，因为线程具有相同的地址空间（虚拟内存共享），同一个进程的线程都具有同一个页表，切换时不需要切换页表。

进程是os分配资源的基本单位，线程是调度的基本单位，cpu调度的是线程。

![image-20240827213923123](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827213923123.png)

# 进程、线程、协程

进程是程序的一次执行过程，是系统运行程序的基本单位，系统运行一个程序就是一个进程从创建、运行到消亡的过程。（Java启动main函数就是启动了一个jvm进程）（这里可以引出jvm）

线程是比进程更小的单位，也叫做轻量级进程，Java中支持多线程，main函数所在线程就是进程主线程（这里可以引出，多线程的优势：利用多核，劣势：上下文切换（什么是上下文切换），线程比进程切换开销小）线程安全（怎么保证正确通信）。

可以从jvm角度说一下，一个进程中的多个线程共享 堆和方法区（最大的一块内存，存放一些公共的：加载的类信息、常量、静态变量），同时各个线程也有自己的小空间（虚拟机栈、本地方法栈保证局部变量不被看到，程序计数器线程能够正确切换）

可以引出协程，https://zhuanlan.zhihu.com/p/172471249

协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。**协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程**，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。

协程比线程更加轻量级！

# 进程间通信的方式有哪些

1. **管道**pipe：半双工通信，数据只能单向流动。如果要双向，就要创建两个管道。
   1. 匿名管道 | , `ps -ef | grep java` 把ps -ef的输出 作为 grep java的输入， 只能在具有亲缘关系（父子进程）的进程间使用， 子进程fork来复制父进程的fd文件描述符，f[1]写，f[0]读
   2. 命名管道， mkfifo myPipe, echo "hello" > myPipe, cat < myPipe， 对亲缘关系没有要求，因为提前创建了类型为管道的设备文件，进程里使用该设备文件，就可以相互通信
2. 信号：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。比如用户调用kill命令将信号发送给其他进程。（异常情况下的工作模式，用信号通知进程）kill -l查看所有信号。 是唯一一种异步通信的机制。
3. **消息队列**MessageQueue：消息队列是由**消息的链表**，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。生命周期随内核。 缺点：通信不及时， 保存在内核里面， 进程写入数据到内核中，用户态数据拷贝到内核态，另一进程读取时，内核态数据拷贝到用户态，存在开销 -》 **共享内存**就是解决这个问题
4. **共享内存**SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。**共享内存是最快的 IPC 方式**，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。多个进程同时修改同一个内存怎么办？使用信号量同步一下。
5. **信号量**Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。**任意时刻共享资源只能被一个进程访问！**
6. 套接字**Socket**：进程间通信机制，与其他通信机制不同的是，它可用于不同机器的进程通信。简单说就是：通信双方的一种约定，用套接字中相关函数来完成通信过程。跨网络与不同主机上的进程之间通信！

# 匿名管道的原理

![image-20240827215347514](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827215347514.png)

# 什么是共享内存啊

现代的os系统，虚拟内存技术，每个进程有自己独立的虚拟内存空间，映射不同的物理内存中

每个进程都有自己独立的页表，用来将进程的虚拟地址映射到物理内存。

> 进程A和进程B启动时，都请求了一块大小为4KB的内存。操作系统为进程A分配了一个虚拟地址0x7fff12340000，并将它映射到物理内存地址0x12340000。然后，操作系统为进程B分配了同样的虚拟地址0x7fff12340000，但将它映射到另一个物理内存地址0x56780000。因此，尽管两个进程有相同的虚拟地址，但它们访问的是不同的物理内存。

共享内存就是， 如果A和B虚拟内存地址相同，访问的物理内存地址也相同。

好处是：A往共享内存里写的东西，B马上就看到，不需要拷贝

原理：os将一块物理内存区域映射到多个进程的虚拟地址空间中。这些进程通过访问映射到相同物理内存的虚拟地址来实现数据的共享。

![image-20240827221429384](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827221429384.png)

# 共享内存和 父子进程的区别

### 1. **父子进程**

父子进程是通过系统调用 `fork()` 产生的。在调用 `fork()` 时，操作系统会创建一个新的进程（子进程），它是父进程的一个副本。子进程继承了父进程的大部分资源，包括文件描述符、环境变量、和内存映射等。

#### 关键点：

- **写时拷贝（Copy-On-Write，COW）**：
  - 在 `fork()` 后，父进程和子进程实际上共享相同的物理内存，但是这些内存页是只读的。当其中一个进程试图修改内存时，操作系统会复制该内存页，使得父进程和子进程拥有独立的内存副本。这就是所谓的“写时拷贝”。
  - 这种机制使得在进程创建时不需要立即复制所有内存，从而提高了性能。
- **独立的地址空间**：
  - 尽管父子进程最初共享相同的物理内存，但它们各自拥有独立的虚拟地址空间。除非显式共享内存，否则它们之后的内存操作互不影响。

### 2. **共享内存**

共享内存是一种进程间通信（IPC）机制，它允许多个进程直接访问相同的一块物理内存区域。共享内存可以通过各种机制实现，如 System V 共享内存、POSIX 共享内存或内存映射文件（`mmap`）。

#### 关键点：

- **共享物理内存**：
  - 在使用共享内存时，多个进程的虚拟地址空间中可能包含相同的虚拟地址，这些虚拟地址映射到同一块物理内存。这意味着不同进程可以通过这一映射同时读取和写入相同的数据。
- **显式控制**：
  - 使用共享内存需要显式地调用相应的API，如 `shmget`（System V）或 `mmap`（POSIX），而不是自动发生的。这与父子进程之间的内存共享机制不同。
- **同步机制**：
  - 由于多个进程可以同时访问共享内存，因此需要使用同步机制（如信号量、互斥锁）来防止数据竞争和保持数据一致性。

### **区别总结**

- **内存共享方式**：
  - **父子进程**：初始状态下共享相同的物理内存，但在修改时通过写时拷贝机制获得独立的内存副本。父子进程通常各自有独立的虚拟地址空间。
  - **共享内存**：显式地将一块物理内存共享给多个进程，所有进程访问相同的物理内存，直接进行通信。
- **应用场景**：
  - **父子进程**：常用于创建新进程、后台任务、服务器进程等。其内存共享是短暂的，通常用于传递初始状态。
  - **共享内存**：用于需要高效的进程间通信、数据共享等场景。适合于需要频繁读写和大量数据传递的应用程序。

# 父子进程写时复制

### 写时拷贝的工作原理

1. **初始状态**：
   - 当 `fork()` 系统调用被执行时，子进程会创建，子进程的虚拟地址空间是父进程虚拟地址空间的一个副本。此时，父进程和子进程实际上共享相同的物理内存页，但这些页是只读的。
   - 操作系统通过将这些共享页的权限标记为只读来实现这个共享。这意味着如果父进程或子进程尝试修改这些共享页，写操作就会触发写时拷贝。
2. **写操作触发写时拷贝**：
   - 当父进程或子进程中的任意一个进程尝试修改共享的内存页时（即对该页执行写操作），处理器会检测到对只读页的写入尝试，并产生一个页面错误（page fault）。
   - 操作系统内核会捕获这个页面错误，并执行写时拷贝机制：
     - 内核会为尝试修改内存页的进程分配一个新的物理页，并将原来共享的内存页内容复制到新的物理页中。
     - 然后，内核更新当前进程的页表，将该虚拟地址映射到新的物理页，并将该页的权限标记为可写。
   - 在完成这些操作之后，写操作继续进行，但这次它作用在新的物理页上，不再影响原来的共享内存页。

### 关键点

- **谁触发，谁复制**：写时拷贝中，只有尝试写入共享页的进程（无论是父进程还是子进程）会触发内存页的复制操作，并负责使用新复制的内存页。另一个进程仍然会继续共享原来的只读页，直到它也尝试写入该页。
- **独立操作**：最终，父进程和子进程将各自拥有独立的物理内存页，而这些页最初来自同一个共享的只读页。

### 

假设在 `fork()` 后，父进程和子进程共享一个只读的物理页 `Page A`。如果子进程首先尝试修改该页：

1. 子进程尝试写入 `Page A`。
2. 页面错误触发，操作系统为子进程分配一个新的物理页 `Page B`，并将 `Page A` 的内容复制到 `Page B`。
3. 子进程的页表更新，将对应虚拟地址映射到新的物理页 `Page B`，并标记为可写。
4. 子进程继续写入 `Page B`。

此时，父进程仍然共享原来的 `Page A`，直到它也尝试写入 `Page A`。如果父进程尝试写入，类似的写时拷贝操作会为它分配新的物理页。

因此，**写时拷贝机制中，哪个进程尝试写入共享页，哪个进程就负责复制该页**。

# mmap

内存映射文件，将文件or设备映射到进程的虚拟地址空间中，使文件内容可以像普通内存一样被访问，显著提升io性能

用于进程间通信IPC，通过映射共享内存区域在多个进程之间共享数据

零拷贝技术的实现方式之一：

# 什么是零拷贝

没有零拷贝的情况下：应用程序 从 磁盘读取文件 并 通过网络发送 经历步骤：

![image-20240827222036851](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827222036851.png)

零拷贝技术通过减少或消除不必要的数据拷贝，提高了数据传输的效率和性能。它在网络传输、大文件传输和其他需要高效数据处理的场景中尤为重要。不同的操作系统提供了不同的实现方式，如 `sendfile`、`mmap`、DMA 等，使得零拷贝成为现代高性能计算和网络服务的关键技术之一。

# 信号量

解决共享内存，多个进程同时写一个地址，发生内容覆盖的问题

![image-20240827222546318](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240827222546318.png)

# 进程调度有哪些算法

- 先来先服务（FCFS, First-Come, First-Served）按照进程到达的**先后顺序**进行服务，即先到达的进程先执行。
- 短作业优先（SJF, Shortest Job First）优先处理预计运行**时间短**的进程。
- 优先级调度（PSA, Priority Scheduling Algorithm）根据进程的**优先级**来分配资源，优先级高的进程优先获得资源（执行）。等待时间 + 要求服务时间 / 要求服务时间
- 时间片轮转（RR, Round-Robin）**将CPU时间分割成一系列的时间片，每个进程被分配一个时间片**，在该时间片中，进程可以执行其代码。时间片用完后，进程被暂停并放到就绪队列的末尾，等待下一次调度。
- 多级反馈队列调度（Multilevel Feedback Queue Scheduling）**设置多个就绪队列**，每个队列的优先级逐渐降低，同时每个队列的执行时间也各不相同。进程根据一定的规则被分配到不同的队列中，并在各自的队列中按时间片轮转的方式执行。

# 用户态、内核态

**用户态**：只能受限的访问内存，运行所有的应用程序

**内核态**： 运行操作系统程序，cpu可以访问内存的所有数据，包括外围设备

**为什么要有用户态和内核态？**

由于**需要限制不同的程序之间的访问能力**, 防止他们获取别的程序的内存数据

# 用户态切换到内核态的三种方式？

![image-20240724151622792](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240724151622792.png)

![image-20240724151644508](img/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%9D%A2%E8%AF%95%E9%A2%98%E5%A4%A7%E5%85%A8/image-20240724151644508.png)

1. 系统调用：主动调用， 系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现， 例如Linux的int 80h中断。
2. 异常：当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，比如缺页异常，这时会触发切换内核态处理异常。
3. 外围设备的中断：当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会由用户态到内核态的切换。

# 操作系统的进程空间

栈区（stack） 由编译器自动分配释放 ，存放函数的参数值，局部变量的值等。

堆区（heap）一般由程序员分配释放， 若程序员不释放，程序结束时可能由OS回收 。

静态区（static）存放全局变量和静态变量的存储

代码区(text) 存放函数体的二进制代码。

线程共享堆区、静态区

# 操作系统内存管理

三种方式：

1. 分段管理：将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）
2. 分页管理：在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的页框，程序加载时，可以将任意一页放入内存中任意一个页框，这些页框不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）
3. 段页式管理：段⻚式管理机制结合了段式管理和⻚式管理的优点。简单来说段⻚式管理机制就是把主存先分成若干段，每个段又分成若干⻚，也就是说 段⻚式管理机制 中段与段之间以及段的内部的都是离散的

# 页面置换算法

FIFO（先进先出）、LRU（最近最久未使用）、OPT（最佳置换算法）

OPT的原理：每次选择当前物理块中的页面在未来长时间不被访问的或未来不再使用的页面进行淘汰

优点：具有较好的性能，可以保证获得最低的缺页率

缺点：过于理想化，但是实际上无法实现（没办法预知未来的页面）

# 死锁的条件、解决方式

- 是什么：A和B都吃着自己碗里的，想着对面锅里的，导致线程被阻塞（这里线程的状态）

- 为什么：（死锁的四个必要条件）

  - 互斥条件：该资源任意一个时刻只由一个线程占用。
  - 请求与保持条件：一个线程因请求资源而阻塞时，对已获得的资源保持不放。
  - 不剥夺条件：线程已获得的资源在未使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。
  - 循环等待条件：若干线程之间形成一种头尾相接的循环等待资源关系。

- 怎么办：怎么检测？怎么避免？

  - 怎么检测：`open . /Library/Java/JavaVirtualMachines/jdk1.8.0_321.jdk/Contents/Home/bin` 打开jconsole 或者 jps+jstack

  - 怎么避免：破坏任意一个必要条件
    - 破坏互斥条件：CAS，乐观锁
    - **破坏请求与保持条件**：一次性申请所有的资源tryLock
    - **破坏不剥夺条件**：占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源，数据库deadlock超时
    - **破坏循环等待条件**：靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件，转账场景


# select、poll、epoll的区别

epoll、poll 和 select 都是用于 I/O 多路复用的系统调用，它们的主要区别在于性能和可扩展性。

1. select：select 是最古老的 I/O 多路复用机制，它有一个缺点就是每次调用 select 都需要将所有的文件描述符集合从用户态拷贝到内核态，这样会带来性能上的损耗。同时，select 对于监视的文件描述符数量有限制，通常是 1024 个。
2. poll：poll 是对 select 的改进，它没有了 select 的文件描述符数量限制，但是仍然存在着每次调用都需要将文件描述符集合从用户态拷贝到内核态的问题。
3. epoll：epoll 是 Linux 特有的 I/O 多路复用机制，它使用**事件通知**的方式来进行 I/O 多路复用，不需要每次调用都将文件描述符集合从用户态拷贝到内核态，因此具有更好的性能和可扩展性。epoll 采用了“就绪列表”来管理文件描述符，当文件描述符就绪时，只需将其加入到就绪列表中，而不需要遍历整个文件描述符集合。

总的来说，epoll 在性能和可扩展性上都优于 select 和 poll，特别是在需要处理大量并发连接的场景下，epoll 的优势更加明显。
