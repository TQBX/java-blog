对一个集合使用自定义排序时，我们就要重写`compareTo()`方法或`compare()`方法

# fail-fast 和 fail-safe

fail-fast快速失败：迭代器遍历时，集合结构被改变，就会抛出异常：ConcurrentModificationException，防止继续遍历

fail-safe安全失败：java.util.concurrent（JUC）下面的都是安全失败的，可以在多线程下并发修改。原理是：遍历时先复制原有集合内容，在拷贝的集合上进行遍历。

> 不要在 foreach 循环里进行元素的 `remove/add` 操作。remove 元素请使用 `Iterator` 方式，如果并发操作，需要对 `Iterator` 对象加锁。

# List

- 有序、可重、可null

相比array：[arraylist](集合源码系列/md/ArrayList源码学习.md)动态扩容、只能对象（基本数据类型要包装类）、增删改

相比vector：[vector](集合源码系列/md/Vector源码学习.md)通过synchronized关键字保证线程安全（还有stack），性能不行

arraylist和[linkedlist](集合源码系列/md/LinkedList 源码学习.md)：

- 实现不同：object数组和双向链表，对应的时间复杂度不一样
- linkedlist没有实现[RandomAccess](集合源码系列/md/小白学Java：奇怪的RandomAccess.md)接口，因为内存地址不连续

！！！！！arraylist扩容机制

1. 默认构造初始化 空数组，增加第一个元素后为10
2. 扩容每次新容量 是 原容量的1.5倍， A+(A>>1)
3. 增删操作基于arraycopy方法，数组拷贝，效率低，尾部插和删还行
4. 线程不安全（用vector（效率低），CopyOnWriteArrayList（推荐））

CopyOnWriteArrayList：

- 底层基于数组实现，写操作会复制新数组，在新数组上操作，读数组在原数组上进行
- 写操作会加锁，写操作结束后把原数组指向新数组
- 适合读多写少的场景，但是可能会读到不是实时最新的数据，适合实时性要求不高的场景

# Set

- 无序（不按照索引的顺序添加）、不可重复（按照equals判断=false）（equals和hashcode）

hashset（哈希表）、linkedhashset（链表+哈希表，FIFO）、treeset（红黑树、元素有序）

# Queue

先进先出、有序

双端队列arraydeque和linkedlist 都实现了deque

优先队列priorityQueue，二叉堆、默认是小顶堆、插入和删除logN

阻塞队列[blockingQueue](多线程并发/md/blockingQueue.md)：队列没元素时一直阻塞，直到有、生产消费模型

- [arrayblockqueue](多线程并发/md/array-blocking-queue.md)、[linkedblockingqueue](多线程并发/md/blocking-queue-linked.md)、[priorityblockingqueue](多线程并发/md/blocking-queue-priority.md)、[synchronousqueue](多线程并发/md/blocking-queue-sync.md)、[delayqueue](多线程并发/md/blocking-queue-delay.md)

# Map

Key - value, 查询o1

## hashmap和hashtable的区别

|                 | hashmap                   | hashtable            |
| --------------- | ------------------------- | -------------------- |
| 线程是否安全    | 不安全                    | 安全（synchronized） |
| 效率            | 高                        | 低                   |
| null key 和 val | 支持nullkey和null val     | 不支持               |
| 默认初始容量    | 16                        | 11                   |
| 指定初始容量    | 扩容为2的幂次tableSizeFor | 直接用指定的         |
| 扩容            | *2                        | *2+1                 |
| 底层            | 链表+红黑树               | 无                   |
| 哈希函数        | 高位低位混合              | 直接hashcode         |

hashset底层就是基于hashmap实现的

## hashmap和treemap的区别

treemap（基于红黑树）还实现了NavigableMap（搜索能力logN）和SortedMap（元素排序能力）接口，：定位大于、小于、子集、逆序、边界等

## ！！！[hashmap的底层实现](集合源码系列/md/Hashmap源码学习.md)

jdk1.8之前：数组+链表，扰动函数得到hash、（n-1)&hash，拉链法解决哈希冲突

jdk1.8之后：数组+链表（阈值8）+红黑树，（n-1)&hash找到位置， put方法：链表长度大于阈值、执行treeifybin，**这时候判断数组长度如果小于64，就优先数组扩容**，否则就转换红黑树（注意、并不是直接树）

负载因子默认0.75，数组中已经存储的元素大于数组长度的75%，引发扩容操作。

> 在理想情况下，即哈希码是随机分布的，桶中节点的数量会遵循泊松分布（Poisson distribution）。对于默认的调整大小阈值0.75，泊松分布的参数大约为0.5

## 哈希函数

将高低位二进制特征混合，防止由高位的细微区别产生的频繁哈希碰撞

```java
    static final int hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
    }
```

## put方法

新生成数组，遍历老数组每个位置上的链表和树，如果是链表，重新计算下标扔到数组去，如果是红黑树，遍历树元素，计算每个元素在新数组的下标位置，如果该位置个数超过8就新建一个树，如果没超过8就是生成一个链表，元素都转移完成后，将新数组赋值给hashmap的table属性

![image-20240724155133451](img/%E9%9B%86%E5%90%88%E7%B1%BB%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/image-20240724155133451.png)

## 长度总是2的幂次方：为什么？

让数据分配均匀、减少哈希冲突、方便取模如果是2的幂次，`hash mod length == hash & (length - 1) `位运算提高效率，方便数组的扩容和增删改的取模

## 多线程导致死循环问题

jdk1.8之前当一个桶位中有多个元素需要进行扩容时，多个线程同时对链表进行操作，头插法可能会导致链表中的节点指向错误的位置，从而形成一个环形链表，进而使得查询元素的操作陷入死循环无法结束。**jdk采用尾插法避免链表倒置**，但实际上还是会出现多线程环境下的数据覆盖问题，建议使用[concurrenthashmap](多线程并发/md/concurrent_hashmap.md)

## Concurenthashmap 的底层原理

jdk1.8之前：分段数组 segment（分段锁：每一个锁只锁容器其中一部分数据）+hashentry数组+ 链表、拉链法解决哈希冲突、并发度是segment个数16

jdk1.8之后：Node数组+链表+红黑树，通过synchronized（优化过了偏向轻量级自旋重量级）+cas来保证，拉链法+红黑树，并发度是Node数组的大小

## 为什么key和value不能为null？

避免二义，如果null为key，无法判断key是否存在，多线程环境下，无法确定key-value是否存在（存在其他线程修改的情况），单线程是可以的（不存在其他线程修改）
