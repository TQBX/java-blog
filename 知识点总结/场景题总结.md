# 故障排查类

## 线上故障排查

硬件故障排查：如果一个实例发生了问题，根据情况选择，要不要着急去重启。如果出现的CPU、内存飙高或者日志里出现了OOM异常

1. 隔离：把这台机器从请求列表里摘除，比如把nginx相关权重设置为0

2. 保留现场：

   1. 系统当前连接：ss -antp > $DUMP_DIR/ss.dump 2>&1

   2. 网络状态统计：netstat -s > $DUMP_DIR/netstat-s.dump 2>&1

   3. 进程资源：ss -antp > $DUMP_DIR/ss.dump 2>&1

   4. cpu资源：

      `mpstat > $DUMP_DIR/mpstat.dump 2>&1`
      `vmstat 1 3 > $DUMP_DIR/vmstat.dump 2>&1`
      `sar -p ALL > $DUMP_DIR/sar-cpu.dump 2>&1`
      `uptime > $DUMP_DIR/uptime.dump 2>&1`

   5. IO资源：iostat -x > $DUMP_DIR/iostat.dump 2>&1

   6. 内存问题：free -h > $DUMP_DIR/free.dump 2>&1

   7. 其他全局：ps -ef 、dmesg、sysctl -a

   8. 进程快照：`${JDK_BIN}jinfo $PID > $DUMP_DIR/jinfo.dump 2>&1`

   9. jstat堆信息：

      `${JDK_BIN}jstat -gcutil $PID > $DUMP_DIR/jstat-gcutil.dump 2>&1`
      `${JDK_BIN}jstat -gccapacity $PID > $DUMP_DIR/jstat-gccapacity.dump 2>&1`

   10. jmap堆信息：`jmap $PID / jmap -heap / jmap -histo / jmap -dump:format=b,file=heap.bin $PID`
   11. jvm执行栈：jstack $PID
   12. 高级替补：kill -3 $PID
   13. 内存泄漏现象：9版本中，jmap被jhsdb jmap替代

3. 问题排查

## 内存溢出

使用jmap命令，导出了一份线上堆栈

使用MAT进行分析，通过对GC Roots的分析，发现了一个非常大的HashMap对象，这个原本是做缓存用的，但是使用了无界缓存，没有设置超时时间orLRU策略，使用上没有重写key对象的hashcode和equals方法，对象无法取出直接造成堆内存占用一直上升。

解决：缓存改为guava的cache，并设置弱引用

内存溢出是一个结果，内存泄漏是原因。

内存溢出的原因有：内存空间不足，配置错误等。一些错误的编程方式，不再被使用的对象，没有被回收，没有及时切断和gc roots的联系，导致内存泄漏。

## CPU飙高

线上应用，单节点运行一段时间后，cpu飙升，怀疑某个业务逻辑计算量大 or 出发死循环，排查到最后发现是gc问题

1. 使用top，查找使用cpu最多的某个进程，记录pid
2. 找到进程中使用cpu最多的某个线程
3. jstack

# 场景算法

## 题目描述

给定a，b两个文件，各存放50亿各URL，每个URL各占64B，内存限制是4G。请找出a，b两个文件共同的URL。

## 解答思路

每个URL占64B，50亿个URL占用的空间大小约为320GB。

$$
5,000,000,000 * 64B \approx 5GB * 64 = 320GB
$$
内存大小只有4GB，因此，我们不可能一次性把所有URL加载到内存中处理，我们可以采用分治的思路：

> 把一个文件中的URL按照某个特征划分为多个小文件，使得每个小文件大小不超过4G，这样就可以分别将这些小文件读到内存中进行处理。

- 首先遍历文件a，对遍历的URL求$$hash(URL) \% 1000$$，根据计算结果把遍历到的URL存储到$$a_0，a_1，a_2……a_{999}$$，这样每个大小约为300MB。
- 使用同样的方法遍历文件b，同样把文件b中的URL分别存储文件$$b_0，b_1，b_2，……b_{999}$$中。
- 处理过后，所有可能相同的URL都在对应的小文件中，即$$a_0$$对应$$b_0$$，$$a_n$$对应$b_n$，$n \in [0, 999]$。不对应的小文件不可能有相同的URL，接下来我们只需要求出这1000对文件中相同的URL即可。
- 遍历$a_i(i \in [0, 999])$，将URL存储到一个HashSet中，然后遍历$b_i(i \in [0, 999])$，中的每个URL，看在HashSet集合中是否存在，若存在，说明是共同的URL，可以把这个URL保存到一个单独的文件中。



## 参考

- 微信公众号：武哥聊编程