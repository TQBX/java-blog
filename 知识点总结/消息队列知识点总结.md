为什么要用消息队列啊？（优点）

使用的时候 有没有什么问题？（缺点）没有绝对的好坏！

和其他的mq比呢？为什么选择其中一个（哪些方面的考虑）

https://cloud.tencent.com/developer/article/2113802

## 项目场景

我们项目有一个场景：每次扣减完库存，都会写入到mq延迟消息，缓慢更新数据库的库存。redis内的预热库存消耗完毕后，发送最终mq消息，更新数据库剩余库存为0。这里用到了延迟消费的特性， 减缓流量峰值高的场景下，应对数据库更新库存压力大的挑战（因为我们不能 Redis 扣减的多快，就直接打到库表上，那样对数据库的压力依然很大，容易打挂）。（削峰）

还有一个场景是，用户中奖后，从用户中奖到发奖，使用mq做异步解耦，因为发奖品的方法不一定就在抽奖系统里，可能是其他通过其他的rpc或http接口来发放（接口可能会超时，会重试，这时候就是卡住）。我们通过异步解耦，中奖后，写一个用户中奖流水+task任务表发送mq记录，记下状态，再发送一个mq消息，等到奖品真正发完以后，更新这个状态。（异步、解耦）

## 有什么问题呢？

加入mq之后，系统更复杂

会有消息消费失败、重复消费等问题！

还会有一致性问题！

### 发送消息失败怎么办？（消息丢失问题、可靠性保证）

这里用mq解耦发奖操作，但是引出了一个问题，mq发送消息失败怎么办，这个奖就不发了？因此，就把发送mq消息这个任务写入数据库，定时任务去扫，消费完成之后，把数据库的消息消费状态更新一下。做一个补偿处理，一定能保证消息被消费掉。 （待消费、开始消费、成功、失败）这里也可以用redis记录每个消息的状态，每个消息要保证唯一。

> 确认机制（生产者确认 + broker 持久化 + 消费者确认）or 集群部署 or 监控预警

> 但其实还是有问题，写入任务失败了怎么办呢？或者，更新状态的时候失败了怎么办呢？
>
> 这里生产者发送消息失败可以通过rabbit mq的几个性质去配置：
>
> 1. 生产者确认机制：开启publisher confirm，broker接受到消息并且存储成功，会返回一个确认消息回来
> 2. 持久化消息，rabbit mq支持队列持久化durable和消息持久化（delivery mode= 2），即使rabbit 服务器重启，持久化的队列也会被恢复， 持久化的消息可以在磁盘上备份，保证消息不丢失
> 3. 消费者确认机制：消费者消费消息后，需要发送ack确认给rabbitmq，如果还没消费，consumer就挂了，rabbitmq会认为该消息未被正确处理，重新把消息投入队列等待其他consumer消费（但是这个会导致重复消费问题，需要业务逻辑层面实现幂等设计）
> 4. 集群部署提高rabbitmq服务的可用性和容灾能力，部分节点出现问题，其他节点能发力
> 5. 预拉取策略调整：避免消费者消费速度慢于生产者的发送速度导致消息积压无法持久化，通过调整prefetch count限制消费者预拉取消息的数量（我的项目设置的是1，每次投递1个，消费完再投递1个
> 6. 监控告警：简历完善的监控系统，实时关注rabbitmq的各项指标，队列深度，磁盘使用率

默认情况下，Spring Boot AMQP使用自动确认auto模式，即一旦消息被消费者接收并开始处理，RabbitMQ就认为该消息已被成功处理。但这种方式在消息处理过程中发生异常时可能会导致消息丢失。

如果需要消费者确认机制，listener需要设置ackMode为manual手动确认。需要监听channel和message，显式调用channel.basicAck()来确认消息已经被成功处理，处理失败可以根据业务逻辑使用basicNack和basicReject。

```java
    @Override
    @RabbitListener(queues = "direct.queue", ackMode = "MANUAL")
    public void onMessage(Message message, Channel channel) throws Exception {
        try {
            // 处理消息逻辑
            processMessage(message);

            // 成功处理后手动确认消息
            long deliveryTag = message.getMessageProperties().getDeliveryTag();
            channel.basicAck(deliveryTag, false);

        } catch (Exception e) {
            // 处理失败，可以选择重新入队列（取决于业务需求）
            if(shouldRequeueOnFailure()) {
                long deliveryTag = message.getMessageProperties().getDeliveryTag();
                channel.basicNack(deliveryTag, false, true);
            } else {
                long deliveryTag = message.getMessageProperties().getDeliveryTag();
                channel.basicReject(deliveryTag, false);
            }
        }
    }
```



### 生产者如果多次发送同一个mq，保证奖品不会超发？（重复消费问题）

用**幂等的设计处理**，mq的消息必须含带具有唯一标识的业务id。比如订单id，奖品id，支付单id。接收mq的系统，通过唯一业务id，更新或者写库的时候查一下有没有消费过，消费过的话就不处理了，可以保证幂等，这样奖品就不会超发。

> rabbit层面：消费者确认 + 生产者确认
>
> 配置死信与重试：重复投递的消息没办法正确处理，可以转到死信队列，设置重试策略和最大重试次数，超过限制就记录日志，报警。

这里涉及到的知识有 全局id怎么保证唯一？（雪花算法生成分布式唯一id，每个服务配置专属的工作节点id和数据中心id，生成唯一的id）

> 基于数据库的唯一键约束也可以
>
> 更新操作考虑：乐观锁（版本号比较，只有版本号未变时才更新） 或 分布式锁，

### 消费mq的过程中，使用多线程会产生什么问题

这是一个非常容易产生事故的问题，本身 MQ 消费就是多个应用分别消费，如果有消费失败的，可以抛异常重试。但如果是一个消费 MQ 的应用，里面写了多线程，就可能会出现大量的 MQ 挤压，消费不过来，导致系统瘫痪。而如果你重启，那么这些拉下来的 MQ 消息也就随时丢失了。

### 消息积压

事前：调整prefetch count限制消费者预拉取消息的数量

消费端宕机？紧急扩容，先修复consumer的问题，多机部署consumer，快速消费

### 消息过期失效

这个没关系，我们有任务表兜底，只要没被消费，状态字段就一直不会更新。


## 为什么不用其他的？

依据项目的需求，时效性+延迟+稳定，选择rabbit

rabbitmq 延迟最低，时效性最强，基于主从实现高可用，消息基本不丢

rocketmq，java开发扩展性好，支持高吞吐10万级，分布式架构支持高可用，消息可靠参数配置正确0丢失

kafka 大数据领域、实时计算、日志收集等，支持高吞吐10万级，分布式高可用，消息可靠参数配置正确0丢失

